# VoiceIntent App â€“ iOS + Flask ML Setup

## ğŸ§  Purpose
This app allows voice-command-based intent recognition. It uses:
- React Native frontend for iOS and Android.
- Speech-to-text (STT) using `@react-native-voice/voice`.
- Flask backend with an ML model to classify intents.
- Optional offline STT with Vosk.

---

## ğŸ“ Project Structure

```
voice-ml/
â”œâ”€â”€ app.py                         â† Flask backend entry point
â”œâ”€â”€ intent_data.csv               â† Training data
â”œâ”€â”€ intent_model.pkl              â† Trained intent classification model
â”œâ”€â”€ model.zip                     â† Zipped model files (probably for Vosk)
â”œâ”€â”€ requirements.txt              â† Backend dependencies list
â”œâ”€â”€ voice_command_recognizer.py   â† Voice command parsing logic
â”œâ”€â”€ voice_intent_trainer.py       â† ML training script
â”œâ”€â”€ model/
â”‚   â””â”€â”€ vosk-model-small-en-us-0.15/ â† Speech recognition model files (unzipped)
â”œâ”€â”€ __pycache__/                  â† Python cache files
â”œâ”€â”€ venv/                         â† (Old virtual environment â€“ unused)
â”œâ”€â”€ venv2/                        â† âœ… Your current working Python virtual environment
â”‚   â”œâ”€â”€ bin/
â”‚   â”œâ”€â”€ lib/
â”‚   â””â”€â”€ pyvenv.cfg
â”œâ”€â”€ VoiceIntentApp/               â† React Native frontend project
â”‚   â”œâ”€â”€ android/
â”‚   â”œâ”€â”€ ios/
â”‚   â”œâ”€â”€ App.js
â”‚   â”œâ”€â”€ index.js
â”‚   â”œâ”€â”€ app.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ babel.config.js
â”‚   â”œâ”€â”€ node_modules/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ ...
```

---

## ğŸ”— Frontend (iOS / React Native)

### ğŸ¤ Speech-to-Text
- Library: `@react-native-voice/voice`
- Converts speech to text, then calls backend for intent recognition.

### ğŸ›‘ iOS Permissions
Add to `ios/VoiceIntentApp/Info.plist`:
```xml
<key>NSMicrophoneUsageDescription</key>
<string>This app uses your mic to listen for commands.</string>
<key>NSSpeechRecognitionUsageDescription</key>
<string>Speech is used to understand what you say.</string>
```

### ğŸ§¹ Common iOS Issues
- Mic not released: fix with `Voice.destroy()` or `Voice.removeAllListeners()`.
- App crashes on 2nd command: usually due to duplicate listeners.
- Hinglish accuracy reduced: model may need Hinglish-specific training.

---

## ğŸŒ Backend (Flask)

### ğŸ”§ Start Server
```bash
cd voice-ml/
source venv2/bin/activate
flask run --host=0.0.0.0 --port=5001
```

### ğŸ“¡ `/predict` Endpoint
`app.py`:
```python
@app.route('/predict', methods=['POST'])
def predict():
    text = request.json['text']
    # Use intent_model.pkl to classify text and return result
```

---

## ğŸ” Frontend â†’ Backend Call
In `App.js`:
```js
const response = await fetch(`http://${backendIP}:5001/predict`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ text }),
});
```
Replace `backendIP` with your Macâ€™s IP via `ifconfig`.

---

## âœ… Scripts Summary

| File | Purpose |
|------|---------|
| `app.py` | Runs Flask server |
| `voice_intent_trainer.py` | Trains and saves `intent_model.pkl` |
| `voice_command_recognizer.py` | Parses intent text |
| `requirements.txt` | Backend dependencies |
| `model.zip` | Zipped Vosk model |
